From e9009e9cc637bd643f09f6a13b572f70e11a3267 Mon Sep 17 00:00:00 2001
From: Jean-Claude Graf <mail@jeanclaudegraf.ch>
Date: Fri, 7 Feb 2025 13:35:53 +0100
Subject: [PATCH 2/2] Add support for guest user

Required adding GDT segment descriptors and selectors for the guest. In
addition all memory has the S/U bit set, to make it available to guest
user.
---
 .../selftests/kvm/include/x86_64/processor.h  | 31 ++++++++
 .../selftests/kvm/lib/x86_64/processor.c      | 72 +++++++++++++++----
 2 files changed, 88 insertions(+), 15 deletions(-)

diff --git a/tools/testing/selftests/kvm/include/x86_64/processor.h b/tools/testing/selftests/kvm/include/x86_64/processor.h
index 25bc61dac5fb..3893a020baf4 100644
--- a/tools/testing/selftests/kvm/include/x86_64/processor.h
+++ b/tools/testing/selftests/kvm/include/x86_64/processor.h
@@ -340,6 +340,37 @@ static inline unsigned int x86_model(unsigned int eax)
 #define PTE_GET_PA(pte)		((pte) & PHYSICAL_PAGE_MASK)
 #define PTE_GET_PFN(pte)        (PTE_GET_PA(pte) >> PAGE_SHIFT)
 
+// As defined in arch/x86/include/asm/segment.h
+#define GDT_ENTRY_KERNEL_CS 2 // star_cs_k
+#define GDT_ENTRY_KERNEL_DS 3 // star_cs_k + 16
+#define GDT_ENTRY_USER_CS_STAR 4 // start_cs_u
+#define GDT_ENTRY_USER_DS 5 // start_cs_u + 8
+#define GDT_ENTRY_USER_CS 6 // start_cs_u + 16
+#define GDT_ENTRY_TSS 8 // Needs two entries
+#define GDT_ENTRY_TSS_2 9
+
+#define __KERNEL_CS (GDT_ENTRY_KERNEL_CS * 8) // 0x10
+#define __KERNEL_DS (GDT_ENTRY_KERNEL_DS * 8) // 0x18
+#define __USER_DS (GDT_ENTRY_USER_DS * 8 + 3) // 0x2b
+#define __USER_CS (GDT_ENTRY_USER_CS * 8 + 3) // 0x33
+#define __USER_CS_STAR (GDT_ENTRY_USER_CS_STAR * 8 + 3) // 0x23
+#define __TSS (GDT_ENTRY_TSS * 8)
+
+// As declared in /arch/x86/include/asm/processor.h
+struct x86_hw_tss {
+	u32 reserved1;
+	u64 sp0;
+	u64 sp1;
+	u64 sp2;
+	u64 reserved2;
+	u64 ist[7];
+	u32 reserved3;
+	u32 reserved4;
+	u16 reserved5;
+	u16 io_bitmap_base;
+
+} __attribute__((packed));
+
 /* General Registers in 64-Bit Mode */
 struct gpr64_regs {
 	u64 rax;
diff --git a/tools/testing/selftests/kvm/lib/x86_64/processor.c b/tools/testing/selftests/kvm/lib/x86_64/processor.c
index d8288374078e..f8cbccc06e49 100644
--- a/tools/testing/selftests/kvm/lib/x86_64/processor.c
+++ b/tools/testing/selftests/kvm/lib/x86_64/processor.c
@@ -14,9 +14,6 @@
 #define NUM_INTERRUPTS 256
 #endif
 
-#define DEFAULT_CODE_SELECTOR 0x8
-#define DEFAULT_DATA_SELECTOR 0x10
-
 #define MAX_NR_CPUID_ENTRIES 100
 
 vm_vaddr_t exception_handlers;
@@ -158,7 +155,7 @@ static uint64_t *virt_create_upper_pte(struct kvm_vm *vm,
 	uint64_t *pte = virt_get_pte(vm, parent_pte, vaddr, current_level);
 
 	if (!(*pte & PTE_PRESENT_MASK)) {
-		*pte = PTE_PRESENT_MASK | PTE_WRITABLE_MASK;
+		*pte = PTE_PRESENT_MASK | PTE_WRITABLE_MASK | PTE_USER_MASK;
 		if (current_level == target_level)
 			*pte |= PTE_LARGE_MASK | (paddr & PHYSICAL_PAGE_MASK);
 		else
@@ -221,7 +218,8 @@ void __virt_pg_map(struct kvm_vm *vm, uint64_t vaddr, uint64_t paddr, int level)
 	pte = virt_get_pte(vm, pde, vaddr, PG_LEVEL_4K);
 	TEST_ASSERT(!(*pte & PTE_PRESENT_MASK),
 		    "PTE already present for 4k page at vaddr: 0x%lx\n", vaddr);
-	*pte = PTE_PRESENT_MASK | PTE_WRITABLE_MASK | (paddr & PHYSICAL_PAGE_MASK);
+	*pte = PTE_PRESENT_MASK | PTE_WRITABLE_MASK | PTE_USER_MASK |
+	       (paddr & PHYSICAL_PAGE_MASK);
 }
 
 void virt_arch_pg_map(struct kvm_vm *vm, uint64_t vaddr, uint64_t paddr)
@@ -437,7 +435,24 @@ static void kvm_seg_fill_gdt_64bit(struct kvm_vm *vm, struct kvm_segment *segp)
  * with the selector value given by @selector.
  */
 static void kvm_seg_set_kernel_code_64bit(struct kvm_vm *vm, uint16_t selector,
-	struct kvm_segment *segp)
+		struct kvm_segment *segp)
+{
+	memset(segp, 0, sizeof(*segp));
+	segp->selector = selector;
+	segp->limit = 0xFFFFFFFFu;
+	segp->s = 0x1; /* kTypeCodeData */
+	segp->type = 0x08 | 0x01 | 0x02; /* kFlagCode | kFlagCodeAccessed
+					  * | kFlagCodeReadable
+					  */
+	segp->g = true;
+	segp->l = true;
+	segp->present = 1;
+	if (vm)
+		kvm_seg_fill_gdt_64bit(vm, segp);
+}
+
+static void kvm_seg_set_user_code_64bit(struct kvm_vm *vm, uint16_t selector,
+		struct kvm_segment *segp)
 {
 	memset(segp, 0, sizeof(*segp));
 	segp->selector = selector;
@@ -449,6 +464,7 @@ static void kvm_seg_set_kernel_code_64bit(struct kvm_vm *vm, uint16_t selector,
 	segp->g = true;
 	segp->l = true;
 	segp->present = 1;
+	segp->dpl = 3;
 	if (vm)
 		kvm_seg_fill_gdt_64bit(vm, segp);
 }
@@ -484,6 +500,23 @@ static void kvm_seg_set_kernel_data_64bit(struct kvm_vm *vm, uint16_t selector,
 		kvm_seg_fill_gdt_64bit(vm, segp);
 }
 
+static void kvm_seg_set_user_data_64bit(struct kvm_vm *vm, uint16_t selector,
+		struct kvm_segment *segp)
+{
+	memset(segp, 0, sizeof(*segp));
+	segp->selector = selector;
+	segp->limit = 0xFFFFFFFFu;
+	segp->s = 0x1; /* kTypeCodeData */
+	segp->type = 0x00 | 0x01 | 0x02; /* kFlagData | kFlagDataAccessed
+					  * | kFlagDataWritable
+					  */
+	segp->g = true;
+	segp->present = true;
+	segp->dpl = 3;
+	if (vm)
+		kvm_seg_fill_gdt_64bit(vm, segp);
+}
+
 vm_paddr_t addr_arch_gva2gpa(struct kvm_vm *vm, vm_vaddr_t gva)
 {
 	int level = PG_LEVEL_NONE;
@@ -516,10 +549,14 @@ static void kvm_setup_tss_64bit(struct kvm_vm *vm, struct kvm_segment *segp,
 
 	memset(segp, 0, sizeof(*segp));
 	segp->base = vm->tss;
-	segp->limit = 0x67;
+	segp->limit = sizeof(struct x86_hw_tss) - 1;
 	segp->selector = selector;
-	segp->type = 0xb;
+	segp->type = 0x9; // 0x9 means available
 	segp->present = 1;
+
+	struct x86_hw_tss *tss = addr_gva2hva(vm, vm->tss);
+	tss->io_bitmap_base = sizeof(struct x86_hw_tss);
+
 	kvm_seg_fill_gdt_64bit(vm, segp);
 }
 
@@ -540,11 +577,15 @@ static void vcpu_setup(struct kvm_vm *vm, struct kvm_vcpu *vcpu)
 		sregs.cr4 |= X86_CR4_PAE | X86_CR4_OSFXSR;
 		sregs.efer |= (EFER_LME | EFER_LMA | EFER_NX);
 
+		struct kvm_segment tmp;
+
 		kvm_seg_set_unusable(&sregs.ldt);
-		kvm_seg_set_kernel_code_64bit(vm, DEFAULT_CODE_SELECTOR, &sregs.cs);
-		kvm_seg_set_kernel_data_64bit(vm, DEFAULT_DATA_SELECTOR, &sregs.ds);
-		kvm_seg_set_kernel_data_64bit(vm, DEFAULT_DATA_SELECTOR, &sregs.es);
-		kvm_setup_tss_64bit(vm, &sregs.tr, 0x18);
+		kvm_seg_set_kernel_code_64bit(vm, __KERNEL_CS, &sregs.cs);
+		kvm_seg_set_kernel_data_64bit(vm, __KERNEL_DS, &sregs.ds);
+		kvm_seg_set_kernel_data_64bit(vm, __KERNEL_DS, &sregs.es);
+		kvm_seg_set_user_code_64bit(vm, __USER_CS, &tmp);
+		kvm_seg_set_user_data_64bit(vm, __USER_DS, &tmp);
+		kvm_setup_tss_64bit(vm, &sregs.tr, __TSS);
 		break;
 
 	default:
@@ -1103,7 +1144,7 @@ void vm_init_descriptor_tables(struct kvm_vm *vm)
 	/* Handlers have the same address in both address spaces.*/
 	for (i = 0; i < NUM_INTERRUPTS; i++)
 		set_idt_entry(vm, i, (unsigned long)(&idt_handlers)[i], 0,
-			DEFAULT_CODE_SELECTOR);
+			__KERNEL_CS);
 }
 
 void vcpu_init_descriptor_tables(struct kvm_vcpu *vcpu)
@@ -1116,9 +1157,10 @@ void vcpu_init_descriptor_tables(struct kvm_vcpu *vcpu)
 	sregs.idt.limit = NUM_INTERRUPTS * sizeof(struct idt_entry) - 1;
 	sregs.gdt.base = vm->gdt;
 	sregs.gdt.limit = getpagesize() - 1;
-	kvm_seg_set_kernel_data_64bit(NULL, DEFAULT_DATA_SELECTOR, &sregs.gs);
+	kvm_seg_set_kernel_data_64bit(NULL, __KERNEL_DS, &sregs.gs);
 	vcpu_sregs_set(vcpu, &sregs);
-	*(vm_vaddr_t *)addr_gva2hva(vm, (vm_vaddr_t)(&exception_handlers)) = vm->handlers;
+	*(vm_vaddr_t *)addr_gva2hva(vm, (vm_vaddr_t)(&exception_handlers)) =
+		vm->handlers;
 }
 
 void vm_install_exception_handler(struct kvm_vm *vm, int vector,
-- 
2.48.1

